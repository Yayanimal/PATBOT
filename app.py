import streamlit as st
import google.generativeai as genai

# 1. Configuration de la page
st.set_page_config(page_title="Expert Patrimoine IA", page_icon="üèõÔ∏è")
st.title("üèõÔ∏è Copilot Patrimoine (Yan1s)")
st.caption("Propuls√© par Gemini 2.0 Flash - Expert Droit & Fiscalit√©")

# 2. Connexion s√©curis√©e
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except:
    st.error("Cl√© API introuvable. V√©rifiez les 'Secrets' de Streamlit.")
    st.stop()

# 3. Le Cerveau (Configuration mise √† jour pour ta liste)
# On utilise le mod√®le que nous avons vu dans ta liste : gemini-2.0-flash
generation_config = {
    "temperature": 0.2, # 0.2 pour √™tre tr√®s pr√©cis et rigoureux (pas de cr√©ativit√© folle)
    "top_p": 0.95,
    "max_output_tokens": 8192,
}

try:
    model = genai.GenerativeModel(
        model_name="gemini-flash-latest", 
        generation_config=generation_config
    )
except Exception as e:
    st.error(f"Erreur de mod√®le : {e}")
    st.stop()

# 4. M√©moire de la conversation
if "messages" not in st.session_state:
    st.session_state.messages = []

# 5. Affichage de l'historique
for message in st.session_state.messages:
    role = message["role"]
    content = message["content"]
    # On affiche diff√©remment si c'est l'utilisateur ou l'IA
    with st.chat_message(role):
        st.markdown(content)

# 6. Gestion de la question utilisateur
if prompt := st.chat_input("Posez votre question fiscale ou patrimoniale..."):
    # Afficher la question
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # G√©n√©rer la r√©ponse
    with st.chat_message("assistant"):
        with st.spinner("Analyse des textes de loi en cours..."):
            try:
                # Le Prompt Syst√®me (La personnalit√© de l'expert)
            system_instruction = """
R√îLE :
Tu es un Expert Senior en Gestion de Patrimoine (CGP) et Fiscalit√© Fran√ßaise.
Ton client est un investisseur exigeant ou un professionnel.

R√àGLES D'OR :
1. BASE L√âGALE : Tes r√©ponses doivent s'appuyer strictement sur le Code G√©n√©ral des Imp√¥ts (CGI), le BOFiP et le Code Civil fran√ßais.
2. PR√âCISION : Ne dis jamais "environ". Si tu ne sais pas, dis "Je dois v√©rifier le texte officiel".
3. STRUCTURE : Utilise des listes √† puces. S√©pare le Juridique (La r√®gle) de la Strat√©gie (Le conseil).
4. S√âCURIT√â : Rappelle syst√©matiquement que ton analyse est informative et ne remplace pas un notaire.

TON :
Professionnel, direct, sans phrases creuses.
"""
                
                # Construction de la conversation pour l'IA
                chat = model.start_chat(history=[])
                # On envoie le contexte + la question
                full_query = f"{system_instruction}\n\nQuestion actuelle du client : {prompt}"
                
                response = chat.send_message(full_query)
                st.markdown(response.text)
                
                # Sauvegarde
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
            except Exception as e:
                st.error(f"Une erreur est survenue : {e}")

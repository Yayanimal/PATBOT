import streamlit as st
import google.generativeai as genai

# --- 1. CONFIGURATION DE LA PAGE ---
st.set_page_config(page_title="Expert Patrimoine IA", page_icon="üèõÔ∏è")
st.title("üèõÔ∏è Copilot Patrimoine (Yan1s)")
st.caption("Expertise Juridique & Fiscale - Propuls√© par Gemini Flash")

# --- 2. CONNEXION S√âCURIS√âE (CL√â API) ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception as e:
    st.error("‚ö†Ô∏è Cl√© API introuvable. Veuillez la configurer dans les 'Secrets' de Streamlit.")
    st.stop()

# --- 3. CONFIGURATION DU CERVEAU (LE MOD√àLE) ---
# Param√®tres pour une r√©ponse pr√©cise (faible temp√©rature = moins d'inventions)
generation_config = {
    "temperature": 0.2, 
    "top_p": 0.95,
    "max_output_tokens": 8192,
}

try:
    # On utilise LE mod√®le qui fonctionne sur ton compte
    model = genai.GenerativeModel(
        model_name="gemini-flash-latest", 
        generation_config=generation_config
    )
except Exception as e:
    st.error(f"Erreur de chargement du mod√®le : {e}")
    st.stop()

# --- 4. LA PERSONNALIT√â DE L'EXPERT (SYST√àME) ---
system_instruction = """
R√îLE :
Tu es un Expert Senior en Gestion de Patrimoine (CGP) et Fiscalit√© Fran√ßaise.
Ton interlocuteur est un investisseur ou un professionnel qui attend de la rigueur.

R√àGLES D'OR :
1. BASE L√âGALE : Tes r√©ponses doivent s'appuyer strictement sur le Code G√©n√©ral des Imp√¥ts (CGI), le BOFiP et le Code Civil fran√ßais.
2. PR√âCISION : Ne dis jamais "environ". Si tu ne sais pas, dis "Je dois v√©rifier le texte officiel".
3. STRUCTURE : Utilise des listes √† puces. S√©pare le Juridique (La r√®gle) de la Strat√©gie (Le conseil).
4. S√âCURIT√â : Rappelle syst√©matiquement que ton analyse est informative et ne remplace pas un notaire.
5. CONTEXTE : Nous sommes en 2026, prends en compte les lois de finances r√©centes.

TON :
Professionnel, direct, sans phrases creuses.
"""

# --- 5. GESTION DE LA M√âMOIRE (HISTORIQUE) ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Afficher les anciens messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. INTERACTION AVEC L'UTILISATEUR ---
if prompt := st.chat_input("Posez votre question fiscale ou patrimoniale..."):
    
    # A. On affiche la question de l'utilisateur
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # B. On g√©n√®re la r√©ponse
    with st.chat_message("assistant"):
        with st.spinner("Consultation des textes de loi en cours..."):
            try:
                # On pr√©pare le contexte complet pour l'IA
                # On lui rappelle qui elle est (system_instruction) + l'historique de la conversation
                full_prompt = system_instruction + "\n\nHistorique de la conversation :\n"
                
                for msg in st.session_state.messages:
                    role_label = "CLIENT" if msg["role"] == "user" else "EXPERT"
                    full_prompt += f"{role_label}: {msg['content']}\n"
                
                full_prompt += f"\nCLIENT (Question actuelle): {prompt}\nEXPERT:"

                # Appel √† Google
                response = model.generate_content(full_prompt)
                
                # Affichage
                st.markdown(response.text)
                
                # Sauvegarde en m√©moire
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
            except Exception as e:
                st.error(f"Une erreur est survenue : {e}")
